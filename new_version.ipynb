{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27309fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset ... \n",
      "load tokenizer ... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model.bert import BERT, MLMHead\n",
    "from utils.molecule_dataloader import MoleculeLangaugeModelDataset, collate_fn\n",
    "from utils.trainer import train, evaluate, predict\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    print(\"load dataset ... \")\n",
    "#     with open(\"data/molecule_net/molecule_total.pickle\", 'rb') as f:\n",
    "#         train_data = pickle.load(f)\n",
    "        \n",
    "#     train_data = train_data[:100000]\n",
    "    with open(\"data/molecule_net/molecule_small.pickle\", \"rb\") as f:\n",
    "        train_data = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    train_data, test_data = train_test_split(train_data, test_size=0.2, shuffle=True, random_state=42)\n",
    "    train_data, valid_data = train_test_split(train_data, test_size=0.2, shuffle=True, random_state=42)\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "def load_tokenizer():\n",
    "    print(\"load tokenizer ... \")\n",
    "    with open(\"data/molecule_net/molecule_tokenizer.pickle\", \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "train_data, valid_data, test_data = load_dataset()\n",
    "tokenizer = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b14ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "d_model = 128\n",
    "dim_feedforward = 512\n",
    "dropout_rate = 0.1\n",
    "pad_token_id = 0\n",
    "nhead = 8\n",
    "num_layers = 8\n",
    "# use_RNN = False\n",
    "use_RNN = True\n",
    "batch_size = 512 * 4\n",
    "masking_rate = 0.15\n",
    "vocab_dim = len(tokenizer[0])\n",
    "learning_rate = 0.0005\n",
    "\n",
    "train_dataset = MoleculeLangaugeModelDataset(data=train_data, seq_len=seq_len, tokenizer=tokenizer, masking_rate=masking_rate)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "valid_dataset = MoleculeLangaugeModelDataset(data=valid_data, seq_len=seq_len, tokenizer=tokenizer, masking_rate=masking_rate)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "test_dataset = MoleculeLangaugeModelDataset(data=test_data, seq_len=seq_len, tokenizer=tokenizer, masking_rate=masking_rate)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "bert_base = BERT(vocab_dim, seq_len, d_model, dim_feedforward, pad_token_id, nhead, num_layers, dropout_rate)\n",
    "model = MLMHead(bert_base, d_model, vocab_dim, use_RNN).to(DEVICE)\n",
    "# model = MLMHead(bert_base, d_model, vocab_dim, use_RNN)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "# scheduler = CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps=200, cycle_mult=1.0,\n",
    "#                                           max_lr=0.005, min_lr=0.00001, warmup_steps=50, gamma=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4021521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "class MoleculeNet(pl.LightningModule):\n",
    "    def __init__(self, learning_rate):\n",
    "        super(MoleculeNet, self).__init__()\n",
    "        \n",
    "        self.bert_base = BERT(vocab_dim, seq_len, d_model, dim_feedforward, pad_token_id, nhead, num_layers, dropout_rate)\n",
    "        self.model = MLMHead(bert_base, d_model, vocab_dim, use_RNN).to(DEVICE)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "#         self.train_accuracy = torchmetrics.Accuracy()\n",
    "#         self.valid_accuracy = torchmetrics.Accuracy()\n",
    "#         self.test_accuracy = torchmetrics.Accuracy()\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, masked_label = batch\n",
    "        \n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y, ignore_index=0)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "#         self.log(\"train_accuracy\", self.train_accuracy(y_hat, y), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, masked_label = batch\n",
    "        \n",
    "        y_hat = self.model(x)\n",
    "#         loss = F.cross_entropy(y_hat, y, ignore_index=0)\n",
    "        \n",
    "        self.log(\"valid_loss\", loss)\n",
    "#         self.log(\"valid_accuracy\", self.valid_accuracy(y_hat, y), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, masked_label = batch\n",
    "        \n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y, ignore_index=0)\n",
    "        \n",
    "        self.log(\"test_loss\", loss)\n",
    "#         self.log(\"test_accuracy\", self.test_accuracy(y_hat, y), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "          \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate, weight_decay=0.1)\n",
    "        \n",
    "        return {\"optimizer\": optimizer}\n",
    "\n",
    "    \n",
    "# def define_callbacks(patience, ckpt_path):\n",
    "#     early_stopping = EarlyStopping('valid_loss', patience=patience)\n",
    "#     check_points = ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\", dirpath=ckpt_path, save_top_k=1)\n",
    "    \n",
    "#     return [early_stopping, check_points]\n",
    "\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "melecule_net = MoleculeNet(LEARNING_RATE)\n",
    "# callbacks = define_callbacks(10, \"./weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45ad77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=N_EPOCHS, enable_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad11f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:118: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(melecule_net, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51facc54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=N_EPOCHS, enable_progress_bar=True)\n",
    "trainer.fit(melecule_net, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87bc84d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8355 | Train Acc: 0.3807\n",
      "Valid Loss: 2.2707 | Valid Acc: 0.3950\n",
      "prediction results: 19.0 %\n",
      "prediction results: 18.83 %\n",
      "prediction results: 18.61 %\n",
      "prediction results: 18.98 %\n",
      "prediction results: 19.19 %\n",
      "Epoch: 0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0240 | Train Acc: 0.3879\n",
      "Valid Loss: 1.7838 | Valid Acc: 0.3894\n",
      "prediction results: 28.07 %\n",
      "prediction results: 27.82 %\n",
      "prediction results: 27.56 %\n",
      "prediction results: 28.02 %\n",
      "prediction results: 28.43 %\n",
      "Epoch: 0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6774 | Train Acc: 0.3817\n",
      "Valid Loss: 1.5246 | Valid Acc: 0.3870\n",
      "prediction results: 33.53 %\n",
      "prediction results: 33.34 %\n",
      "prediction results: 33.0 %\n",
      "prediction results: 33.61 %\n",
      "prediction results: 34.08 %\n",
      "Epoch: 0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4626 | Train Acc: 0.3815\n",
      "Valid Loss: 1.3479 | Valid Acc: 0.3874\n",
      "prediction results: 34.4 %\n",
      "prediction results: 34.21 %\n",
      "prediction results: 33.87 %\n",
      "prediction results: 34.52 %\n",
      "prediction results: 34.9 %\n",
      "Epoch: 0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3255 | Train Acc: 0.3822\n",
      "Valid Loss: 1.2434 | Valid Acc: 0.3854\n",
      "prediction results: 37.17 %\n",
      "prediction results: 36.95 %\n",
      "prediction results: 36.6 %\n",
      "prediction results: 37.25 %\n",
      "prediction results: 37.8 %\n",
      "Epoch: 0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2430 | Train Acc: 0.3831\n",
      "Valid Loss: 1.1785 | Valid Acc: 0.3903\n",
      "prediction results: 37.79 %\n",
      "prediction results: 37.61 %\n",
      "prediction results: 37.22 %\n",
      "prediction results: 37.91 %\n",
      "prediction results: 38.51 %\n",
      "Epoch: 0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1915 | Train Acc: 0.3826\n",
      "Valid Loss: 1.1374 | Valid Acc: 0.3883\n",
      "prediction results: 38.08 %\n",
      "prediction results: 37.81 %\n",
      "prediction results: 37.55 %\n",
      "prediction results: 38.15 %\n",
      "prediction results: 38.69 %\n",
      "Epoch: 0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1568 | Train Acc: 0.3819\n",
      "Valid Loss: 1.1092 | Valid Acc: 0.3892\n",
      "prediction results: 38.32 %\n",
      "prediction results: 38.09 %\n",
      "prediction results: 37.85 %\n",
      "prediction results: 38.5 %\n",
      "prediction results: 39.04 %\n",
      "Epoch: 0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1332 | Train Acc: 0.3820\n",
      "Valid Loss: 1.0894 | Valid Acc: 0.3867\n",
      "prediction results: 38.72 %\n",
      "prediction results: 38.51 %\n",
      "prediction results: 38.09 %\n",
      "prediction results: 38.68 %\n",
      "prediction results: 39.32 %\n",
      "Epoch: 0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1177 | Train Acc: 0.3824\n",
      "Valid Loss: 1.0766 | Valid Acc: 0.3890\n",
      "prediction results: 38.93 %\n",
      "prediction results: 38.62 %\n",
      "prediction results: 38.38 %\n",
      "prediction results: 38.95 %\n",
      "prediction results: 39.62 %\n",
      "Epoch: 0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1072 | Train Acc: 0.3820\n",
      "Valid Loss: 1.0676 | Valid Acc: 0.3869\n",
      "prediction results: 39.09 %\n",
      "prediction results: 38.8 %\n",
      "prediction results: 38.59 %\n",
      "prediction results: 39.22 %\n",
      "prediction results: 39.74 %\n",
      "Epoch: 0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1012 | Train Acc: 0.3828\n",
      "Valid Loss: 1.0634 | Valid Acc: 0.3866\n",
      "prediction results: 39.19 %\n",
      "prediction results: 38.94 %\n",
      "prediction results: 38.64 %\n",
      "prediction results: 39.25 %\n",
      "prediction results: 39.92 %\n",
      "Epoch: 0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0961 | Train Acc: 0.3841\n",
      "Valid Loss: 1.0589 | Valid Acc: 0.3870\n",
      "prediction results: 39.28 %\n",
      "prediction results: 39.0 %\n",
      "prediction results: 38.7 %\n",
      "prediction results: 39.31 %\n",
      "prediction results: 39.93 %\n",
      "Epoch: 0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0923 | Train Acc: 0.3841\n",
      "Valid Loss: 1.0562 | Valid Acc: 0.3879\n",
      "prediction results: 39.22 %\n",
      "prediction results: 39.03 %\n",
      "prediction results: 38.76 %\n",
      "prediction results: 39.37 %\n",
      "prediction results: 39.98 %\n",
      "Epoch: 0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0911 | Train Acc: 0.3841\n",
      "Valid Loss: 1.0557 | Valid Acc: 0.3895\n",
      "prediction results: 39.29 %\n",
      "prediction results: 39.03 %\n",
      "prediction results: 38.76 %\n",
      "prediction results: 39.41 %\n",
      "prediction results: 39.99 %\n",
      "Epoch: 0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0917 | Train Acc: 0.3838\n",
      "Valid Loss: 1.0573 | Valid Acc: 0.3895\n",
      "prediction results: 39.31 %\n",
      "prediction results: 39.07 %\n",
      "prediction results: 38.75 %\n",
      "prediction results: 39.44 %\n",
      "prediction results: 39.95 %\n",
      "Epoch: 0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0935 | Train Acc: 0.3840\n",
      "Valid Loss: 1.0600 | Valid Acc: 0.3869\n",
      "prediction results: 39.28 %\n",
      "prediction results: 39.02 %\n",
      "prediction results: 38.77 %\n",
      "prediction results: 39.45 %\n",
      "prediction results: 40.02 %\n",
      "Epoch: 0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0963 | Train Acc: 0.3853\n",
      "Valid Loss: 1.0629 | Valid Acc: 0.3888\n",
      "prediction results: 39.29 %\n",
      "prediction results: 39.03 %\n",
      "prediction results: 38.73 %\n",
      "prediction results: 39.36 %\n",
      "prediction results: 39.9 %\n",
      "Epoch: 0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0999 | Train Acc: 0.3834\n",
      "Valid Loss: 1.0664 | Valid Acc: 0.3861\n",
      "prediction results: 39.23 %\n",
      "prediction results: 38.95 %\n",
      "prediction results: 38.71 %\n",
      "prediction results: 39.31 %\n",
      "prediction results: 39.9 %\n",
      "Epoch: 0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1035 | Train Acc: 0.3849\n",
      "Valid Loss: 1.0705 | Valid Acc: 0.3891\n",
      "prediction results: 39.13 %\n",
      "prediction results: 38.89 %\n",
      "prediction results: 38.62 %\n",
      "prediction results: 39.26 %\n",
      "prediction results: 39.87 %\n",
      "Epoch: 0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7/32 [00:06<00:22,  1.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cc0d07ada737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch:04}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Attentional_DTI/utils/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device, clip)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# N_EPOCHS = 100\n",
    "# PAITIENCE = 10\n",
    "# start_epoch = 0\n",
    "# n_paitience = 0\n",
    "# best_valid_loss = float('inf')\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# project_name = \"BERT_deargen_similar\"\n",
    "# output_path = f\"output/{project_name}\"\n",
    "# weight_path = f\"weights/{project_name}\"\n",
    "\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "# os.makedirs(weight_path, exist_ok=True)\n",
    "   \n",
    "# for epoch in range(start_epoch, N_EPOCHS):\n",
    "#     print(f'Epoch: {epoch:04}')\n",
    "\n",
    "#     train_loss, train_accuracy = train(model, train_dataloader, optimizer, criterion, DEVICE)\n",
    "#     valid_loss, valid_accuracy = evaluate(model, valid_dataloader, optimizer, criterion, DEVICE)\n",
    "\n",
    "#     scheduler.step(valid_loss)\n",
    "\n",
    "#     print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.4f}\\nValid Loss: {valid_loss:.4f} | Valid Acc: {valid_accuracy:.4f}')\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "\n",
    "#         for i, (X, target, masking_label) in enumerate(test_dataloader):\n",
    "#             if i < 5:\n",
    "#                 output = model(X.to(\"cuda\"))\n",
    "#                 output_ = torch.argmax(output.clone().detach().to(\"cpu\"), axis=-1)\n",
    "#                 target_ = target.clone().detach().to(\"cpu\")\n",
    "#                 print(f\"prediction results: {np.round((torch.sum(output_ == target_) / torch.numel(output_)).numpy() * 100, 2)} %\")\n",
    "#             else:\n",
    "#                 break\n",
    "    \n",
    "#     with open(os.path.join(output_path, \"log.txt\"), \"a\") as f:\n",
    "#         f.write(\"epoch: {0:04d} train loss: {1:.4f}, train acc: {2:.4f}, test loss: {3:.4f}, test acc: {4:.4f}\\n\".format(epoch, train_loss, train_accuracy, valid_loss, valid_accuracy))\n",
    "\n",
    "#     if n_paitience < PAITIENCE:\n",
    "#         if best_valid_loss > valid_loss:\n",
    "#             best_valid_loss = valid_loss\n",
    "#             torch.save(model.state_dict(), os.path.join(weight_path, 'MoleculeNet_LM_best.pt'))\n",
    "#             n_paitience = 0\n",
    "#         elif best_valid_loss <= valid_loss:\n",
    "#             n_paitience += 1\n",
    "#     else:\n",
    "#         print(\"Early stop!\")\n",
    "#         model.load_state_dict(torch.load(os.path.join(weight_path, 'MoleculeNet_LM_best.pt')))\n",
    "#         model.eval()\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c587b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
