{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8f3029",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/interaction/kiba/train_molecule.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12625/1447363121.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180595841/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  data = torch.tensor([d.squeeze(0).numpy() for d in data])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/interaction/kiba/train_protein.npy\n",
      "data/interaction/kiba/train_y.npy\n",
      "data/interaction/kiba/valid_molecule.npy\n",
      "data/interaction/kiba/valid_protein.npy\n",
      "data/interaction/kiba/valid_y.npy\n",
      "data/interaction/kiba/test_molecule.npy\n",
      "data/interaction/kiba/test_protein.npy\n",
      "data/interaction/kiba/test_y.npy\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    def get_split_dataset(mode):\n",
    "        dataset = {}\n",
    "        for f in [\"molecule\", \"protein\", \"y\"]:\n",
    "            f_path = os.path.join(path, mode + \"_\" + f + \".npy\")\n",
    "            print(f_path)\n",
    "            data = np.load(f_path, allow_pickle=True)\n",
    "            try:\n",
    "                data = torch.tensor([d.squeeze(0).numpy() for d in data])\n",
    "            except:\n",
    "                data = torch.tensor(data)\n",
    "            dataset[f] = data\n",
    "            \n",
    "        return dataset\n",
    "            \n",
    "    train_data = get_split_dataset(\"train\")\n",
    "    valid_data = get_split_dataset(\"valid\")\n",
    "    test_data = get_split_dataset(\"test\")\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "    \n",
    "train_data, valid_data, test_data = load_dataset(\"data/interaction/kiba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38044664",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_data['molecule'], train_data['protein'], train_data['y'])\n",
    "valid_dataset = TensorDataset(valid_data['molecule'], valid_data['protein'], valid_data['y'])\n",
    "test_dataset = TensorDataset(test_data['molecule'], test_data['protein'], test_data['y'])\n",
    "    \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, num_workers=16, \n",
    "                              shuffle=True, pin_memory=True, prefetch_factor=10, \n",
    "                              drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=512, num_workers=16, \n",
    "                              shuffle=False, pin_memory=True, prefetch_factor=10, \n",
    "                              drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, num_workers=16, \n",
    "                             shuffle=False, pin_memory=True, prefetch_factor=10, \n",
    "                             drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b37a8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConcatenateDTI(\n",
       "  (mol_proj): Linear(in_features=128, out_features=512, bias=True)\n",
       "  (prot_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc_1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc_out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConcatenateDTI(nn.Module):\n",
    "    def __init__(self, molecule_dim=128, protein_dim=1024, inner_dim=512, projection=True):\n",
    "        super().__init__()\n",
    "        self.is_projection = projection\n",
    "\n",
    "        if self.is_projection:\n",
    "            self.mol_proj = nn.Linear(molecule_dim, inner_dim)        \n",
    "            self.prot_proj = nn.Linear(protein_dim, inner_dim)            \n",
    "            self.fc_1 = nn.Linear(inner_dim * 2, inner_dim)\n",
    "        else:\n",
    "            self.fc_1 = nn.Linear(molecule_dim + protein_dim, inner_dim)\n",
    "        \n",
    "        self.fc_2 = nn.Linear(inner_dim, int(inner_dim / 2))\n",
    "        self.fc_out = nn.Linear(int(inner_dim / 2), 1)\n",
    "   \n",
    "\n",
    "    def forward(self, molecule, protein):\n",
    "        if self.is_projection:\n",
    "            molecule = self.mol_proj(molecule)\n",
    "            protein = self.prot_proj(protein)\n",
    "            \n",
    "        x = torch.cat((molecule, protein), -1)\n",
    "        x = F.dropout(F.gelu(self.fc_1(x)), 0.1)\n",
    "        x = F.dropout(F.gelu(self.fc_2(x)), 0.1)\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "concatenate_dti = ConcatenateDTI()\n",
    "concatenate_dti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.trainer.supporters import CombinedLoader\n",
    "\n",
    "\n",
    "class DTI_prediction(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.MeanAbsoluteError()\n",
    "        self.valid_accuracy = torchmetrics.MeanAbsoluteError()\n",
    "        self.test_accuracy = torchmetrics.MeanAbsoluteError()\n",
    "        \n",
    "        \n",
    "    def forward(self, molecule, protein):\n",
    "        return self.model(molecule, protein)\n",
    "   \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        molecule = batch[0]\n",
    "        protein = batch[1]\n",
    "        y = batch[2]\n",
    "        \n",
    "        y_hat = self(molecule, protein).squeeze(-1)        \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_accuracy\", self.train_accuracy(y_hat, y), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "        \n",
    "    def valid_step(self, batch, batch_idx):\n",
    "        molecule = batch[0]\n",
    "        protein = batch[1]\n",
    "        y = batch[2]\n",
    "        \n",
    "        y_hat = self(molecule, protein).squeeze(-1)        \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        \n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"valid_accuracy\", self.valid_accuracy(y_hat, y), on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        molecule = batch[0]\n",
    "        protein = batch[1]\n",
    "        y = batch[2]\n",
    "        \n",
    "        y_hat = self(molecule, protein).squeeze(-1)        \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        \n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_accuracy\", self.test_accuracy(y_hat, y), on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        molecule = batch[0]\n",
    "        protein = batch[1]\n",
    "        y = batch[2]\n",
    "        \n",
    "        y_hat = self(molecule, protein).squeeze(-1)        \n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100)\n",
    "    \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "    \n",
    "    \n",
    "callbacks = [\n",
    "    ModelCheckpoint(monitor='valid_loss', save_top_k=20, dirpath='weights/DTI_prediction_CLS_token_concatenate', filename='attentional_dti-{epoch:03d}-{valid_loss:.4f}-{valid_accuracy:.4f}'),\n",
    "]\n",
    "\n",
    "model = DTI_prediction(\n",
    "    model=concatenate_dti\n",
    ")\n",
    "\n",
    "# remove precision 16, because prot bert trained using full precision\n",
    "trainer = pl.Trainer(max_epochs=1000, gpus=1, enable_progress_bar=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3095e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = \"\"\n",
    "# model.load_from_checkpoint(model=concatenate_dti, checkpoint_path=\"weights/DTI_prediction_CLS_token_concatenate/\" + checkpoint_file)\n",
    "\n",
    "# trainer.test(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
