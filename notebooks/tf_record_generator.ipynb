{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea4a075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93673016/93673016 [03:16<00:00, 476307.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "def generate_vocab(corpus):\n",
    "    token_index = 4\n",
    "    stoi, itos = {}, {}\n",
    "    \n",
    "    stoi[\"<PAD>\"], itos[0] = 0, \"<PAD>\"\n",
    "    stoi[\"<CLS>\"], itos[1] = 1, \"<CLS>\"   \n",
    "    stoi[\"<SEP>\"], itos[2] = 2, \"<SEP>\"\n",
    "    stoi[\"<MASK>\"], itos[3] = 3, \"<MASK>\"\n",
    "\n",
    "    for line in tqdm(corpus):\n",
    "        for token in line:\n",
    "            if token not in stoi:\n",
    "                itos[token_index] = token\n",
    "                stoi[token] = token_index\n",
    "                token_index += 1\n",
    "\n",
    "    return stoi, itos\n",
    "\n",
    "\n",
    "pickle_path = \"data/molecule_net/molecule_total.pickle\"\n",
    "\n",
    "with open(pickle_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "molecule_stoi, molecule_itos = generate_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b1f0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tain_data: 74938408 valid_data: 9367301 test_data: 9367307\n"
     ]
    }
   ],
   "source": [
    "index_ = int(len(data) * 0.1)\n",
    "\n",
    "train_data = data[:index_*8]\n",
    "valid_data = data[index_*8:index_*9]\n",
    "test_data = data[index_*9:]\n",
    "\n",
    "print(f\"tain_data: {len(train_data)} valid_data: {len(valid_data)} test_data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2d80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def serialize_example(data, stoi, output_path):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    \n",
    "    for smiles in tqdm(data):\n",
    "        feature = {}\n",
    "        \n",
    "        token = [1] + [stoi[s] for s in smiles] + [2]\n",
    "        feature['smiles'] = _bytes_feature(bytes(smiles, \"utf-8\"))\n",
    "        feature['token'] = _float_feature(token)\n",
    "        \n",
    "        features = tf.train.Features(feature=feature)\n",
    "        example = tf.train.Example(features=features)\n",
    "        serialized = example.SerializeToString()\n",
    "        \n",
    "        writer.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f728cb9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74938408/74938408 [1:07:35<00:00, 18480.44it/s]\n",
      "100%|██████████| 9367301/9367301 [08:24<00:00, 18569.28it/s]\n",
      "100%|██████████| 9367307/9367307 [08:25<00:00, 18543.45it/s]\n"
     ]
    }
   ],
   "source": [
    "train_output_path = \"data/molecule_net/molecule_train.tfrecord\"\n",
    "valid_output_path = \"data/molecule_net/molecule_valid.tfrecord\"\n",
    "test_output_path = \"data/molecule_net/molecule_test.tfrecord\"\n",
    "\n",
    "serialize_example(train_data, molecule_stoi, train_output_path)\n",
    "serialize_example(valid_data, molecule_stoi, valid_output_path)\n",
    "serialize_example(test_data, molecule_stoi, test_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418e96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/molecule_net/molecule_tokenizer\", \"wb\") as f:\n",
    "    pickle.dump([molecule_stoi, molecule_itos], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5305b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_tfrecord():\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {\n",
    "            'smiles': tf.io.FixedLenFeature([], tf.string),\n",
    "            'token':  tf.io.FixedLenFeature([], tf.float32)\n",
    "        }\n",
    "        \n",
    "        x = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return parse_tfrecord\n",
    "\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_name, batch_size, shuffle=True, buffer_size=10240):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    \n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = raw_dataset.map(\n",
    "        _parse_tfrecord(),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c4d1127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ParseSingleExample/ParseExample/ParseExampleV2:1\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {smiles: (None,), token: (None,)}, types: {smiles: tf.string, token: tf.float32}>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_tfrecord_dataset(\"data/molecule_net/molecule_small.tfrecord\", 1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44096b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
