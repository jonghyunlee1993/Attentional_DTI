{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e27502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torchtext import data, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# with open(\"data/chem_total.pickle\", 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "with open(\"data/molecule_small.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bea053a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC1=CC=C(C=C1)N2C(=CC(=C2C)C(=O)CN3CCN(CC3)CC(=O)NC4=C(C=CC=C4C)C)C'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fbe6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "SRC = torchtext.legacy.data.Field(tokenize=None,\n",
    "                                init_token='<CLS>',\n",
    "                                eos_token='<SEP>',\n",
    "                                pad_token='<PAD>',\n",
    "                                unk_token='<MASK>',\n",
    "                                lower=False,\n",
    "                                batch_first=False,\n",
    "                                include_lengths=False)\n",
    "\n",
    "SRC.build_vocab(data, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf7560d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC1=CC=C(C=C1)N2C(=CC(=C2C)C(=O)CN3CCN(CC3)CC(=O)NC4=C(C=CC=C4C)C)C']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.preprocess(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67306fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<MASK>',\n",
       " '<PAD>',\n",
       " '<CLS>',\n",
       " '<SEP>',\n",
       " 'C',\n",
       " '=',\n",
       " '(',\n",
       " ')',\n",
       " 'N',\n",
       " 'O',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " 'S',\n",
       " 'F',\n",
       " 'l',\n",
       " '5',\n",
       " '[',\n",
       " ']',\n",
       " '-',\n",
       " '+',\n",
       " '#',\n",
       " 'B',\n",
       " 'r',\n",
       " '6',\n",
       " 'I',\n",
       " '7',\n",
       " 'H',\n",
       " '8']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7add79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularLangaugeModelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, seq_len=128, masking_rate=0.15):\n",
    "        super(MolecularLangaugeModelDataset, self).__init__()\n",
    "\n",
    "        self.data          = data        \n",
    "        self.tokenizer     = tokenizer\n",
    "        self.vocab         = tokenizer.vocab\n",
    "        self.seq_len       = seq_len\n",
    "        self.masking_rate  = masking_rate\n",
    "        \n",
    "        self.cls_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.init_token]\n",
    "        self.sep_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.eos_token]\n",
    "        self.pad_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.pad_token]\n",
    "        self.mask_token_id = self.tokenizer.vocab.stoi[self.tokenizer.unk_token]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        target = self.tokenizer.numericalize(self.data[idx]).squeeze()\n",
    "        \n",
    "        if len(target) < self.seq_len - 2:\n",
    "            pad_length = self.seq_len - len(target) - 2\n",
    "        else:\n",
    "            target = target[:self.seq_len-2]\n",
    "            pad_length = 0\n",
    "               \n",
    "        masked_sent, masking_label = self.masking(target)\n",
    "        \n",
    "        # MLM\n",
    "        train = torch.cat([\n",
    "            torch.tensor([self.cls_token_id]), \n",
    "            masked_sent,\n",
    "            torch.tensor([self.sep_token_id]),\n",
    "            torch.tensor([self.pad_token_id] * pad_length)\n",
    "        ]).long().contiguous()\n",
    "        \n",
    "        target = torch.cat([\n",
    "            torch.tensor([self.cls_token_id]), \n",
    "            target,\n",
    "            torch.tensor([self.sep_token_id]),\n",
    "            torch.tensor([self.pad_token_id] * pad_length)\n",
    "        ]).long().contiguous()\n",
    "        \n",
    "        masking_label = torch.cat([\n",
    "            torch.zeros(1), \n",
    "            masking_label,\n",
    "            torch.zeros(1),\n",
    "            torch.zeros(pad_length)\n",
    "        ])\n",
    "                \n",
    "        segment_embedding = torch.zeros(target.size(0))\n",
    "        \n",
    "        return train, target, segment_embedding, masking_label\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        for x in self.data:\n",
    "            yield x\n",
    "            \n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "    \n",
    "    # TODO mask 안에서 random 으로 바꿔주는 것 추가\n",
    "    def masking(self, x):\n",
    "        x             = torch.tensor(x).long().contiguous()\n",
    "        masking_idx   = torch.randperm(x.size()[0])[:round(x.size()[0] * self.masking_rate) + 1]       \n",
    "        masking_label = torch.zeros(x.size()[0])\n",
    "        masking_label[masking_idx] = 1\n",
    "        x             = x.masked_fill(masking_label.bool(), self.mask_token_id)\n",
    "        \n",
    "        return x, masking_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da5f33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4, 4,  ..., 1, 1, 1],\n",
      "        [2, 4, 0,  ..., 1, 1, 1],\n",
      "        [2, 4, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [2, 4, 4,  ..., 1, 1, 1],\n",
      "        [2, 4, 9,  ..., 1, 1, 1],\n",
      "        [2, 4, 4,  ..., 1, 1, 1]])\n",
      "tensor([[2, 4, 4,  ..., 1, 1, 1],\n",
      "        [2, 4, 9,  ..., 1, 1, 1],\n",
      "        [2, 4, 8,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [2, 4, 4,  ..., 1, 1, 1],\n",
      "        [2, 4, 9,  ..., 1, 1, 1],\n",
      "        [2, 4, 4,  ..., 1, 1, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-d0a8450635fa>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x             = torch.tensor(x).long().contiguous()\n"
     ]
    }
   ],
   "source": [
    "dataset = MolecularLangaugeModelDataset(data, SRC, seq_len=128, masking_rate=0.15)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "for train, target, sengment_embedding, masking_label in data_loader:\n",
    "    print(train)\n",
    "    print(target)\n",
    "#     print(sengment_embedding)\n",
    "#     print(masking_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b28619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<CLS>CC1CCCCC1NC(=O)C(=CC2=CC(=C(C=C2)OC)[N+](=O)[O-])C#N<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>COC1=CC=CC=C1C2=NN=C(O2)SCC3=CN=C(C=C3)Cl<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>CN(C)C(CNC(=O)C1CCN(CC1)C2=NN3C(=NN=C3C(F)(F)F)C=C2)C4=CC(=CC=C4)OC<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>COC1=CC=CC=C1CNC(=O)CSCC2=CC=CC3=CC=CC=C32<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>CC1=NC2=CC=CC=C2C(=C1)C(=O)NC3=NC(=C(S3)C4=NC=CN4C)C<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>CC1C(OC2=CC=CC=C2O1)C(=O)NCCC3=CN4C=CC=CC4=N3<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>C=CCNC(=O)CN1CCN(CC1)CC2=CC3=C(C=C2)OCC3<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>CCN(CC)S(=O)(=O)N1CCCC1C2=C(C=C(C=C2)OC)OC<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>COCCCN1C(=O)C(N2C1=NC3=CC=CC=C32)CC(=O)NC4=CC=CC=C4<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n",
       " '<CLS>CC1=CC=C(C=C1)CN2C(=C(C(=N2)C)C(=O)OCC3=CN=C(C=C3)Cl)Cl<SEP><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode(x, tokenizer):\n",
    "    results = []\n",
    "    for line in x:\n",
    "        decoded = \"\"\n",
    "        for s in line:\n",
    "            decoded += tokenizer.vocab.itos[s]\n",
    "        results.append(decoded)\n",
    "        \n",
    "    return results\n",
    "\n",
    "decode(target, SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1ece7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
