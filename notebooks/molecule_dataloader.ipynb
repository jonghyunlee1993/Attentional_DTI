{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e27502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torchtext import data, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "with open(\"../data/molecule_net/molecule_small.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bea053a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC1=CC=C(C=C1)N2C(=CC(=C2C)C(=O)CN3CCN(CC3)CC(=O)NC4=C(C=CC=C4C)C)C'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94fbe6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "SRC = torchtext.legacy.data.Field(tokenize=None,\n",
    "                                init_token='<CLS>',\n",
    "                                eos_token='<SEP>',\n",
    "                                pad_token='<PAD>',\n",
    "                                unk_token='<MASK>',\n",
    "                                lower=False,\n",
    "                                batch_first=False,\n",
    "                                include_lengths=False)\n",
    "\n",
    "SRC.build_vocab(data, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf7560d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC1=CC=C(C=C1)N2C(=CC(=C2C)C(=O)CN3CCN(CC3)CC(=O)NC4=C(C=CC=C4C)C)C']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.preprocess(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67306fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<MASK>',\n",
       " '<PAD>',\n",
       " '<CLS>',\n",
       " '<SEP>',\n",
       " 'C',\n",
       " '=',\n",
       " '(',\n",
       " ')',\n",
       " 'N',\n",
       " 'O',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " 'S',\n",
       " 'F',\n",
       " 'l',\n",
       " '5',\n",
       " '[',\n",
       " ']',\n",
       " '-',\n",
       " '+',\n",
       " '#',\n",
       " 'B',\n",
       " 'r',\n",
       " '6',\n",
       " 'I',\n",
       " '7',\n",
       " 'H',\n",
       " '8']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7add79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularLangaugeModelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, seq_len=128, masking_rate=0.15):\n",
    "        super(MolecularLangaugeModelDataset, self).__init__()\n",
    "\n",
    "        self.data          = data        \n",
    "        self.tokenizer     = tokenizer\n",
    "        self.vocab         = tokenizer.vocab\n",
    "        self.seq_len       = seq_len\n",
    "        self.masking_rate  = masking_rate\n",
    "        \n",
    "        self.cls_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.init_token]\n",
    "        self.sep_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.eos_token]\n",
    "        self.pad_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.pad_token]\n",
    "        self.mask_token_id = self.tokenizer.vocab.stoi[self.tokenizer.unk_token]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        target = self.tokenizer.numericalize(self.data[idx]).squeeze()\n",
    "        \n",
    "        if len(target) < self.seq_len - 2:\n",
    "            pad_length = self.seq_len - len(target) - 2\n",
    "        else:\n",
    "            target = target[:self.seq_len-2]\n",
    "            pad_length = 0\n",
    "               \n",
    "        masked_sent, masking_label = self.masking(target)\n",
    "        \n",
    "        # MLM\n",
    "\n",
    "        train = torch.cat([\n",
    "            torch.tensor([self.cls_token_id]), \n",
    "            masked_sent,\n",
    "            torch.tensor([self.sep_token_id])\n",
    "        ]).long().contiguous()\n",
    "\n",
    "        target = torch.cat([\n",
    "            torch.tensor([self.cls_token_id]), \n",
    "            target,\n",
    "            torch.tensor([self.sep_token_id])\n",
    "        ]).long().contiguous()\n",
    "\n",
    "        masking_label = torch.cat([\n",
    "            torch.zeros(1), \n",
    "            masking_label,\n",
    "            torch.zeros(1)\n",
    "        ])\n",
    "\n",
    "        segment_embedding = torch.zeros(target.size(0))\n",
    "        \n",
    "        return train, target, segment_embedding, masking_label\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        for x in self.data:\n",
    "            yield x\n",
    "            \n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "    \n",
    "    # TODO mask 안에서 random 으로 바꿔주는 것 추가\n",
    "    def masking(self, x):\n",
    "        x             = torch.tensor(x).long().contiguous()\n",
    "        masking_idx   = torch.randperm(x.size()[0])[:round(x.size()[0] * self.masking_rate) + 1]       \n",
    "        masking_label = torch.zeros(x.size()[0])\n",
    "        masking_label[masking_idx] = 1\n",
    "        x             = x.masked_fill(masking_label.bool(), self.mask_token_id)\n",
    "        \n",
    "        return x, masking_label\n",
    "    \n",
    "    \n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "#     data = pack_sequence(data, enforce_sorted=False)\n",
    "    \n",
    "#     target = [item[1] for item in batch]\n",
    "#     segment_embedding = [item[2] for item in batch]\n",
    "#     masking_label = [item[3] for item in batch]  \n",
    "    \n",
    "    return [data, target, segment_embedding, masking_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1da5f33d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([ 2,  2,  4,  4,  9,  4,  4,  8, 10,  6,  5,  4,  4,  4,  4,  7,  0, 14,\n",
      "         4,  6,  0,  0,  4,  9,  0,  7,  4,  0, 10,  5,  7,  0,  4,  0,  8,  0,\n",
      "        11,  4,  4,  4,  4,  9,  8,  0,  0, 10,  4,  5,  4,  4, 11,  4,  7,  5,\n",
      "         0,  4,  4,  6,  6,  4,  5,  5,  9,  4,  7, 10,  8,  7,  4,  4,  4, 16,\n",
      "         0,  3,  5,  4,  4,  6,  5,  0,  6,  4,  6,  5,  4, 12,  0,  9,  4,  7,\n",
      "         9,  4,  0,  9,  0,  3]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=tensor([0, 1]), unsorted_indices=tensor([0, 1]))\n",
      "[tensor([ 2,  4,  9,  4, 10,  5,  4,  4,  5,  4,  6,  4,  5,  4, 10,  7,  4,  8,\n",
      "        11,  4,  4,  8,  6,  4,  4, 11,  7,  4,  4,  6,  5,  9,  7,  8,  4,  4,\n",
      "        12,  5,  4,  4,  6,  5,  4,  6,  4,  6,  5,  4, 12,  7,  9,  4,  7,  9,\n",
      "         4,  7,  9,  4,  3]), tensor([ 2,  4,  4,  8,  6,  4,  4,  7, 14,  6,  5,  9,  7,  6,  5,  9,  7,  8,\n",
      "         4,  4,  9,  4, 10,  5,  4,  4,  5,  4,  6,  4,  5,  4, 10,  7,  4, 16,\n",
      "         3])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-8af8fd34905b>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x             = torch.tensor(x).long().contiguous()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sengment_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-6148368df810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msengment_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sengment_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_sequence\n",
    "\n",
    "dataset = MolecularLangaugeModelDataset(data, SRC, seq_len=128, masking_rate=0.15)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "for train, target, segment_embedding, masking_label in data_loader:\n",
    "    print(train)\n",
    "    print(target)\n",
    "    print(sengment_embedding)\n",
    "    print(masking_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8b28619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<CLS>CC1=CC(=C(N1)C)C(=O)CSC2=NN=C(N2C)C3=CC=CC=C3Cl<SEP>',\n",
       " '<CLS>CCCCN(C1=C(N(C(=O)NC1=O)CCC)N)C(=O)C2=CN(N=N2)CC3=CC=CC=C3<SEP>',\n",
       " '<CLS>CC1=C(SC=N1)CCC(=O)NCC2CCN(C2)C3=CC(=O)N(N=C3)C<SEP>',\n",
       " '<CLS>COC(=O)C1=C(OC=C1)COC(=O)CCC2=CNC3=CC=CC=C32<SEP>',\n",
       " '<CLS>COC1=C(C=C(C=C1)F)C(=O)NC2=C(C(=C(C=C2)F)F)F<SEP>',\n",
       " '<CLS>CC(CC1=NC=CN=C1)NC2CCN(CC2)C3=CC=CC(=C3)C4=CSC=N4<SEP>',\n",
       " '<CLS>COC1=CC(=C(C=C1NCC(=O)NCCC2=CC=C(C=C2)F)OC)Cl<SEP>',\n",
       " '<CLS>C1CC(CN(C1)C(=O)C2=CC=CC3=CC=CC=C32)C(=O)N4CCNC(=O)C4<SEP>',\n",
       " '<CLS>CC1=CC(=O)C(=NN1C2=CC=CC=C2F)C(=O)N3CCNC(=O)C3<SEP>',\n",
       " '<CLS>COC1=CC=CC(=C1OC)C(=O)NC2CCCC(C2)C(F)(F)F<SEP>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode(x, tokenizer):\n",
    "    results = []\n",
    "    for line in x:\n",
    "        decoded = \"\"\n",
    "        for s in line:\n",
    "            decoded += tokenizer.vocab.itos[s]\n",
    "        results.append(decoded)\n",
    "        \n",
    "    return results\n",
    "\n",
    "decode(target, SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1ece7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
