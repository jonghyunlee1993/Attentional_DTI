{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Drug_ID                                               Drug  \\\n",
      "0         11314340  CC1=C2C=C(C3=CN=CC(OCC(N)CC4=CC=CC=C4)=C3)C=CC...   \n",
      "1         11314340  CC1=C2C=C(C3=CN=CC(OCC(N)CC4=CC=CC=C4)=C3)C=CC...   \n",
      "2         11314340  CC1=C2C=C(C3=CN=CC(OCC(N)CC4=CC=CC=C4)=C3)C=CC...   \n",
      "3         11314340  CC1=C2C=C(C3=CN=CC(OCC(N)CC4=CC=CC=C4)=C3)C=CC...   \n",
      "4         11314340  CC1=C2C=C(C3=CN=CC(OCC(N)CC4=CC=CC=C4)=C3)C=CC...   \n",
      "...            ...                                                ...   \n",
      "138547  53358942.0  COC1=CC(C(=O)O)=CC=C1NC(=O)[C@@H]1N[C@@H](CC(C...   \n",
      "138548  53476877.0  CC(C)(C)C[C@@H]1N[C@@H](C(=O)N[C@H]2CC[C@H](O)...   \n",
      "138549  58573469.0  CC(C)[C@@H](CS(=O)(=O)C(C)C)N1C(=O)[C@@](C)(CC...   \n",
      "138550    113557.0                        CCCCCCCOC1OC(CO)C(O)C(O)C1O   \n",
      "138551    113557.0                        CCCCCCCOC1OC(CO)C(O)C(O)C1O   \n",
      "\n",
      "       Target_ID                                             Target         Y  \n",
      "0          ABL1p  PFWKILNPLLERGTYYYFMGQQPGKVLGDQRRPSLPALHFIKGAGK...  4.999996  \n",
      "1           ABL2  MVLGTVLLPPNSYGRDQDTSLCCLCTEASESALPDLTDHFASCVED...  4.999996  \n",
      "2         ACVR1B  MAESAGASSFFPLVVLLLAGSGGSGPRGVQALLCACTSCLQANYTC...  4.999996  \n",
      "3         ACVRL1  MTLGSPRKGLLMLLMALVTQGDPVKPSRGPLVTCTCESPHCKGPTC...  4.999996  \n",
      "4          ADCK3  MAAILGDTIMVAKGLVKLTQAAVETHLQHLGIGGELIMAARALQST...  4.999996  \n",
      "...          ...                                                ...       ...  \n",
      "138547       NaN  MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...  9.602060  \n",
      "138548       NaN  MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...  8.552842  \n",
      "138549       NaN  MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...  9.838632  \n",
      "138550    P08191  MKRVITLFAVLLMGWSVNAWSFACKTANGTAIPIGGGSANVYVNLA...  7.767004  \n",
      "138551    P08191  MKRVITLFAVLLMGWSVNAWSFACKTANGTAIPIGGGSANVYVNLA...  7.718967  \n",
      "\n",
      "[138552 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torchtext.legacy import data, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "with open(\"data/DTI_train.pickle\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = data.Field(tokenize=None,\n",
    "                 init_token='<CLS>',\n",
    "                 eos_token='<SEP>',\n",
    "                 pad_token='<PAD>',\n",
    "                 unk_token='<MASK>',\n",
    "                 lower=False,\n",
    "                 batch_first=False,\n",
    "                 include_lengths=False)\n",
    "\n",
    "SRC.build_vocab(df.Target.values, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/DTI/protein_vocab.pickle\", \"wb\") as f:\n",
    "    pickle.dump(SRC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<MASK>',\n",
       " '<PAD>',\n",
       " '<CLS>',\n",
       " '<SEP>',\n",
       " 'L',\n",
       " 'S',\n",
       " 'E',\n",
       " 'G',\n",
       " 'A',\n",
       " 'V',\n",
       " 'K',\n",
       " 'P',\n",
       " 'R',\n",
       " 'D',\n",
       " 'T',\n",
       " 'I',\n",
       " 'Q',\n",
       " 'N',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'H',\n",
       " 'M',\n",
       " 'C',\n",
       " 'W',\n",
       " 'X']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, seq_len=128, masking_rate=0.15):\n",
    "        super(ProteinDataset, self).__init__()\n",
    "\n",
    "        self.data          = data        \n",
    "        self.tokenizer     = tokenizer\n",
    "        self.vocab         = tokenizer.vocab\n",
    "        self.seq_len       = seq_len\n",
    "        self.masking_rate  = masking_rate\n",
    "        \n",
    "        self.cls_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.init_token]\n",
    "        self.sep_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.eos_token]\n",
    "        self.pad_token_id  = self.tokenizer.vocab.stoi[self.tokenizer.pad_token]\n",
    "        self.mask_token_id = self.tokenizer.vocab.stoi[self.tokenizer.unk_token]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        target = self.tokenizer.numericalize(self.data[idx]).squeeze()\n",
    "        \n",
    "        if len(target) < self.seq_len - 2:\n",
    "            pad_length = self.seq_len - len(target) - 2\n",
    "        else:\n",
    "            target = target[:self.seq_len-2]\n",
    "            pad_length = 0\n",
    "               \n",
    "        masked_sent, masking_label = self.masking(target)\n",
    "        \n",
    "        # MLM\n",
    "        train = torch.cat([\n",
    "            torch.tensor([self.cls_token_id]), \n",
    "            masked_sent,\n",
    "            torch.tensor([self.sep_token_id]),\n",
    "            torch.tensor([self.pad_token_id] * pad_length)\n",
    "        ]).long().contiguous()\n",
    "        \n",
    "        target = torch.cat([\n",
    "            torch.tensor([self.cls_token_id]), \n",
    "            target,\n",
    "            torch.tensor([self.sep_token_id]),\n",
    "            torch.tensor([self.pad_token_id] * pad_length)\n",
    "        ]).long().contiguous()\n",
    "        \n",
    "        masking_label = torch.cat([\n",
    "            torch.zeros(1), \n",
    "            masking_label,\n",
    "            torch.zeros(1),\n",
    "            torch.zeros(pad_length)\n",
    "        ])\n",
    "                \n",
    "        segment_embedding = torch.zeros(target.size(0))\n",
    "        \n",
    "        return train, target, segment_embedding, masking_label\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        for x in self.data:\n",
    "            yield x\n",
    "            \n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "    \n",
    "    def masking(self, x):\n",
    "        x             = torch.tensor(x).long().contiguous()\n",
    "        masking_idx   = torch.randperm(x.size()[0])[:round(x.size()[0] * self.masking_rate) + 1]       \n",
    "        masking_label = torch.zeros(x.size()[0])\n",
    "        masking_label[masking_idx] = 1\n",
    "        x             = x.masked_fill(masking_label.bool(), self.mask_token_id)\n",
    "        \n",
    "        return x, masking_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 11, 18,  ..., 11,  8,  3],\n",
      "        [ 2, 21,  7,  ...,  0,  0,  3],\n",
      "        [ 2,  0,  5,  ...,  7,  0,  3],\n",
      "        ...,\n",
      "        [ 2,  0,  8,  ..., 14, 18,  3],\n",
      "        [ 2, 21, 12,  ..., 10, 18,  3],\n",
      "        [ 2, 21,  5,  ...,  7, 16,  3]])\n",
      "tensor([[ 2, 11, 18,  ..., 11,  8,  3],\n",
      "        [ 2, 21,  7,  ..., 19, 13,  3],\n",
      "        [ 2, 21,  5,  ...,  7,  9,  3],\n",
      "        ...,\n",
      "        [ 2, 21,  8,  ..., 14, 18,  3],\n",
      "        [ 2, 21, 12,  ..., 10, 18,  3],\n",
      "        [ 2, 21,  5,  ...,  7, 16,  3]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-8274485ca497>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x             = torch.tensor(x).long().contiguous()\n"
     ]
    }
   ],
   "source": [
    "dataset = ProteinDataset(df.Target.values, SRC, seq_len=256, masking_rate=0.15)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "for train, target, sengment_embedding, masking_label in data_loader:\n",
    "    print(train)\n",
    "    print(target)\n",
    "#     print(sengment_embedding)\n",
    "#     print(masking_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
